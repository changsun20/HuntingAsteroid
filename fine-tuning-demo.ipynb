{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(directory):\n",
    "    # 获取目录下的所有文件和子目录\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        \n",
    "        # 判断是否为文件\n",
    "        if os.path.isfile(file_path):\n",
    "            # 删除文件\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            # 如果是目录，则递归调用函数删除子目录中的文件\n",
    "            delete_files(file_path)\n",
    "            # 删除空目录\n",
    "            os.rmdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up():\n",
    "    delete_files('.\\\\preprocess\\\\train\\\\positive')\n",
    "    delete_files('.\\\\preprocess\\\\train\\\\negative')\n",
    "    delete_files('.\\\\preprocess\\\\val\\\\positive')\n",
    "    delete_files('.\\\\preprocess\\\\val\\\\negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.file_list = []\n",
    "        self.labels = []\n",
    "\n",
    "        positive_dir = os.path.join(data_dir, 'positive')\n",
    "        negative_dir = os.path.join(data_dir, 'negative')\n",
    "\n",
    "        positive_files = os.listdir(positive_dir)\n",
    "        negative_files = os.listdir(negative_dir)\n",
    "\n",
    "        self.file_list.extend(positive_files)\n",
    "        self.file_list.extend(negative_files)\n",
    "\n",
    "        self.labels.extend(['positive'] * len(positive_files))\n",
    "        self.labels.extend(['negative'] * len(negative_files))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.data_dir, self.labels[idx], file_name)\n",
    "        data = np.load(file_path)['matrix1']\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            if 'train' in file_path:\n",
    "                data = self.transform['train'](data)\n",
    "            elif 'val' in file_path:\n",
    "                data = self.transform['val'](data)\n",
    "\n",
    "        return data, label\n",
    "\n",
    "# 自定义转换函数，将numpy数组转换为PyTorch张量\n",
    "def numpy_to_tensor(sample):\n",
    "    return torch.from_numpy(sample)\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        numpy_to_tensor,\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        numpy_to_tensor,\n",
    "        transforms.Normalize((0.5,), (0.2,))\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '.\\\\preprocess'\n",
    "\n",
    "image_datasets = {x: CustomDataset(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = ['positive', 'negative']  # 如果您的数据集有类别标签，可以在这里添加类别名\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\1. Yau2023\\HuntingAsteroid\\fine-tuning-demo.ipynb 单元格 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/1.%20Yau2023/HuntingAsteroid/fine-tuning-demo.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mpause(\u001b[39m0.001\u001b[39m)  \u001b[39m# pause a bit so that plots are updated\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/1.%20Yau2023/HuntingAsteroid/fine-tuning-demo.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Get a batch of training data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/1.%20Yau2023/HuntingAsteroid/fine-tuning-demo.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m inputs, classes \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/1.%20Yau2023/HuntingAsteroid/fine-tuning-demo.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Make a grid from batch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/1.%20Yau2023/HuntingAsteroid/fine-tuning-demo.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m out \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(inputs)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloader['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt201gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
